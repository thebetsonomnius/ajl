---

title: "initiation"

date: 2023-04-18

---

welcome to the endtimes

<!-- more -->

It is regrettable that the initiation of the slow takeoff apparently requires the mass privatization of top-shelf intellects. It is not however unpredictable - previous technological movements in American life were preceded by the brief relocation of the intellectual elite to locked rooms. The Title 50-ing of algebraic topologists and combinatorics theorists in the 1970s and 80s to work on cryptographic projects for the NSA's then-nascent scalable surveillance program led quite directly to the dot-com boom of the 90s. In the 40s, every German-trained physicist in the world was placed under lock and key in the American southwest to build devices that produced the 20th century world order and much of the peacetime technological innovations that spawned the digital revolution. But, neither the dot-com boom nor the commercialization of nuclear missile technology live on the same order of magnitude as the advent of [Yemlems](https://ajl.bio/definitions#yemlems). The distinction in significance has thus far not been accompanied by a similar increase in the quality of the public discourse. This is due to the rapid move to venture-capitalize the previously open-source research labs at the frontier of the [field](https://ajl.bio/definitions#deep-learning). Privatization in deep learning is by no means a novel phenomenon - in 2017, Qualcomm [effectively gutted](https://www.qualcomm.com/news/releases/2017/08/qualcomm-bolsters-position-artificial-intelligence-research-outlines-its) one of the world's most illustrious particle physics departments in their pursuit of research talent. What is different in the current wave of close-sourcing is the power of the technology being restricted and the nature of the people producing it. In previous deep learning privatizations, old legends of the field with no pretentions to open-source fundamentalism gathered their most loyal graduates and strapped them into a golden parachute. What was being purchased by the corporations wasn't technology - it was connections and basic familiarity with a then-foreign and poorly understood field. This time around, it's the 20-somethings that are leading the charge, and the venture capitalists across the table know that what they're buying is not prestige, but implementation wisdom. Training a Yemlem is a high-stakes affair. Compute costs run well into the 10s of millions, the return on capital is low, and the training runs themselves take months to execute. While it is not [all that difficult](https://ajl.bio/2023/04/20/so-you-want-to-train-a-yemlem.html) to train one to the well-initiated, VCs face a very high risk profile in taking a $90 million dollar 6-month gamble on a trio of twenty-somethings who claim they can build Skynet. Anyone with a proven record of achievement even tangentially related to the design and manufacture of Yemlems is now a multimillion dollar commodity, due merely to the anxiolytic effect their resume has on whoever's hiring or funding them. Money has a way of holding the attention of those receiving it, particularly when they're researchers in a previously capital-bottlenecked field who've suddenly been granted free access to a billion-dollar bank account. The intellectual vacuum left behind by the rapid exit of the top young minds from public intellectual discourse has been filled by a somewhat amorphous group I've termed the [Yuddites](https://ajl.bio/definitions#Yuddite). Yuddites share in common an affinity for [blogging](https://lesswrong.com), ignoring mathematics, [Kurzweil syndrome](https://ajl.bio/definitions#kurzweil-syndrome), and [voiding their life's work without realizing it](https://www.lesswrong.com/posts/nH4c3Q9t9F3nJ7y8W/gpts-are-predictors-not-imitators). At their best, they were the last vanguard of intellectual adventurism west of the Mississippi, in the dark days following the Uber IPO exodus and preceding the [AI revival](https://cerebralvalley.ai/). Today, they are purveyors of [Bostromite](https://nickbostrom.com) nonsense who corrupt the public discourse on AGI by spewing ill-founded and self-contradictory nonsense into the societal media. The primary goal of this series of posts will be to systematically deconstruct the Yuddites' arguments in no particular order of quality. The secondary goal, to be pursued simultaneously, will be to reconstruct the Yuddites' intellectual program in a manner consonant with the relevant mathematical and empirical results. AGI is in fact a present threat, but the nature of the threat and its dynamical properties have been severely misconstrued.

"initiation" will be the dryest of the posts in this series. It's more of a syllabus than a post. I anticipate a semi-daily post rate, not subject to extended recursions related to [terminology definitions](https://ajl.bio/definitions), and dev sprints for [indxd](https://indxd.co) & forwardpass. At some point in the next week, I'm going to embed a chat oracle on the site, and a hybrid keyword-neural retriever powered by indxd. It'll be secure - don't go endpoint panning in the bundle. Unless you're a pro pen tester (or are part of some imaginary working group at Adept fine-tuning active [Zemlems](https://ajl.bio/definitions#zemlems) on Phrack), you're better off just paying for [ChatGPT+](https://openai.com/blog/chatgpt-plus). In addition, I'm writing an actively maintained [best practices](https://ajl.bio/2023/04/20/so-you-want-to-train-a-yemlem.html) on training foundation Yemlems, and a (somewhat skeletal atm) [active research program](https://ajl.bio/outrunning-kakade-with-no-rigor.html) for minimal-cost Yemlem alignment.

The first 2 posts in this series will be: 
1. > [Residual Streams, Stochastic Depth Regularization, and Gradient Hacking](https://ajl.bio/2023/04/19/residual-streams-and-gradient-hacking.html)
2. > [NP Completeness and Yemlem Alignment](https://np-completeness-and-alignment.html)

